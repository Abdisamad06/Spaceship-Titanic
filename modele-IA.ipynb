{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902a9ab9",
   "metadata": {},
   "source": [
    "##                                                Entraînement du Modéle IA\n",
    "### Importation des modules \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import joblib\n",
    "### A - Chargement de données d'entraînement\n",
    "# Charger le dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Afficher les premières lignes du dataset\n",
    "data.head()\n",
    "Nous allons supprimer les colonnes qui sont unitile pour l'entrainement de notre modele. Dans notre dataset nous juste la colonne name qui est unitile. \n",
    "data.drop(columns=[\"Name\"], inplace=True)\n",
    "\n",
    "### B - Préparation des données\n",
    "\n",
    "#### 1- Gestion des variables manquantes\n",
    "Nous allons d'abord vérifier les variables manquantes dans les données en utilisant isnull().\n",
    "data.isnull().sum()\n",
    "for col in ['HomePlanet', 'Destination', 'VIP']:\n",
    "    data[col] = data[col].fillna(data[col].mode()[0])\n",
    "\n",
    "data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "\n",
    "\n",
    "cols_depenses = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "data.loc[data['CryoSleep'].isna() & (data[cols_depenses].sum(axis=1) > 0), 'CryoSleep'] = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for col in cols_depenses:\n",
    "    mediane = data[col].median()\n",
    "    data[col] = data[col].fillna(mediane)\n",
    "data.isnull().sum()\n",
    "colonnes_cibles = [\"CryoSleep\", \"Cabin\"]\n",
    "data_cleaned = data.dropna(subset=colonnes_cibles)\n",
    "\n",
    "data_cleaned.info()\n",
    "#### 2- Transformation des données\n",
    "data_cleaned['CryoSleep'] = data_cleaned['CryoSleep'].astype(bool)\n",
    "\n",
    "\n",
    "data_cleaned.info()\n",
    "\n",
    "data_cleaned = data_cleaned.copy()\n",
    "\n",
    "data_cleaned['GroupId'] = data_cleaned['PassengerId'].apply(lambda x: x.split('_')[0])\n",
    "group_sizes = data_cleaned['GroupId'].value_counts()\n",
    "data_cleaned['GroupSize'] = data_cleaned['GroupId'].map(group_sizes)\n",
    "data_cleaned.drop([\"GroupId\", \"PassengerId\"], axis=1, inplace=True)\n",
    "\n",
    "data_cleaned[['Deck','Cabin_Num','Side']]=data_cleaned['Cabin'].str.split(\"/\",expand = True)\n",
    "data_cleaned.drop(['Cabin'], axis=1, inplace=True)\n",
    "\n",
    "cols_depenses = ['RoomService','FoodCourt','Spa','VRDeck']\n",
    "data_cleaned['TotalSpend'] = data_cleaned[cols_depenses].sum(axis =1)\n",
    "\n",
    "data_cleaned.head()\n",
    "\n",
    "colonne =  [\"CryoSleep\",\"VIP\",\"Transported\",\"Cabin_Num\"]\n",
    "data_cleaned[colonne] = data_cleaned[colonne].astype(int)\n",
    "\n",
    "data_cleaned.info()\n",
    "colonne =  [\"Cabin_Num\",\"GroupSize\"]\n",
    "data_cleaned[colonne] = data_cleaned[colonne].astype(float)\n",
    "\n",
    "data_cleaned.info()\n",
    "## C - Encodage et normalisation\n",
    "### 1 - Encodage des variables categorielles\n",
    "categorical_cols = ['HomePlanet', 'Destination', 'Deck', 'Side']\n",
    "data_encoded = pd.get_dummies(data_cleaned, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "bool_columns = data_encoded.select_dtypes(include='bool').columns\n",
    "data_encoded[bool_columns] = data_encoded[bool_columns].astype(int)\n",
    "\n",
    "data_encoded.head()\n",
    "### 2 - Normalisation des variables numeriques\n",
    "numeric_cols = [\n",
    "    'Age', 'RoomService', 'FoodCourt', 'ShoppingMall',\n",
    "    'Spa', 'VRDeck', 'Cabin_Num', 'GroupSize', 'TotalSpend'\n",
    "]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_encoded[numeric_cols] = scaler.fit_transform(data_encoded[numeric_cols])\n",
    "\n",
    "data_encoded.head()\n",
    "Je récupère le scaler utilisé pour la normalisation afin de l'utiliser dans mon interface Streamlit.\n",
    "colonnes_modele = data_encoded.columns.tolist()\n",
    "joblib.dump(colonnes_modele, \"colonnes_modele.joblib\")\n",
    "\n",
    "joblib.dump(scaler , \"scarler2.joblib\")\n",
    "Je sépare les variables caractéristiques de la variable cible.\n",
    "\n",
    "cible = data_encoded['Transported']\n",
    "carac = data_encoded.drop(columns=['Transported'], axis=1)  \n",
    "\n",
    "# D - Modèles\n",
    "Les données ont été divisées en un jeu d'entraînement et un jeu de test pour évaluer les performances du modèle.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(carac, cible, test_size=0.3, random_state=42)\n",
    "### 1- Régerssion Logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
    "print(\"Matrice de Confusion (Régression Logistique) :\\n\", conf_matrix_log_reg)\n",
    "\n",
    "# Rapport de classification\n",
    "class_report_log_reg = classification_report(y_test, y_pred_log_reg)\n",
    "print(\"Rapport de Classification (Régression Logistique) :\\n\", class_report_log_reg)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc_log_reg = roc_auc_score(y_test, y_pred_log_reg)\n",
    "print(\"AUC-ROC (Régression Logistique) :\\n\", roc_auc_log_reg)\n",
    "\n",
    "\n",
    "### 2 - Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix_tree = confusion_matrix(y_test, y_pred_tree)\n",
    "print(\"Matrice de Confusion (Decision Tree) :\\n\", conf_matrix_tree)\n",
    "\n",
    "# Rapport de classification\n",
    "class_report_tree = classification_report(y_test, y_pred_tree)\n",
    "print(\"Rapport de Classification (Decision Tree) :\\n\", class_report_tree)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc_tree = roc_auc_score(y_test, y_pred_tree)\n",
    "print(\"AUC-ROC (Decision Tree) :\\n\", roc_auc_tree)\n",
    "### 3- Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "print(\"Matrice de Confusion :\\n\", conf_matrix_svm)\n",
    "\n",
    "# Rapport de classification\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "print(\"Rapport de Classification :\\n\", class_report_svm)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc_svm = roc_auc_score(y_test, y_pred_svm)\n",
    "print(\"AUC-ROC :\\n\", roc_auc_svm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452402d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24bb9403",
   "metadata": {},
   "source": [
    "### 4 - Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15548b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "\n",
    "perceptron = Perceptron(max_iter=1000, random_state=42, tol=1e-3)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_perceptron = perceptron.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix_perceptron = confusion_matrix(y_test, y_pred_perceptron)\n",
    "print(\"Matrice de Confusion \\n\", conf_matrix_perceptron)\n",
    "\n",
    "# Rapport de classification\n",
    "class_report_perceptron = classification_report(y_test, y_pred_perceptron)\n",
    "print(\"Rapport de Classification:\\n\", class_report_perceptron)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc_perceptron = roc_auc_score(y_test, y_pred_perceptron)\n",
    "print(\"AUC-ROC :\\n\", roc_auc_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f147f2f7",
   "metadata": {},
   "source": [
    "### 5 -Naive Bayès\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "print(\"Matrice de Confusion (Naive Bayes) :\\n\", conf_matrix_nb)\n",
    "\n",
    "# Rapport de classification\n",
    "class_report_nb = classification_report(y_test, y_pred_nb)\n",
    "print(\"Rapport de Classification (Naive Bayes) :\\n\", class_report_nb)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
    "print(\"AUC-ROC (Naive Bayes) :\\n\", roc_auc_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342bdd5a",
   "metadata": {},
   "source": [
    "### 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dac917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialisation et entraînement du modèle\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Matrice de confusion\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Matrice de Confusion (Random Forest) :\\n\", conf_matrix_rf)\n",
    "\n",
    "# Rapport de classification\n",
    "class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(\"Rapport de Classification (Random Forest) :\\n\", class_report_rf)\n",
    "\n",
    "# AUC-ROC\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "print(\"AUC-ROC (Random Forest) :\\n\", roc_auc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f3fd11",
   "metadata": {},
   "source": [
    "### 7 - Modèle final\n",
    "Notre modèle final est le svm et on l'exporte  avec `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93300ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(svm , \"modele_svm.joblib\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
